{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jmgbfqAKOsxR"
   },
   "source": [
    "# Plan of Action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RxEzjKuOPr5n"
   },
   "source": [
    "**Our age prediction CNN model shall be defined and trained by**:\n",
    "1. Importing **training and test datasets** from Google Drive Input Sub-folder\n",
    "2. **Training dataset is already augmented** and has 234,000 images\n",
    "3. **Greyscaling images** instead of using RGB color images\n",
    "4. Defining our intuitively **distributed classes of age-ranges**\n",
    "5. Using **60 epochs** on our **optimized CNN Architecture**, comprising of:\n",
    "    - an input *Conv2D* layer (with 32 filters) paired with an *AveragePooling2D* layer,\n",
    "    - 3 pairs of *Conv2D* (with 64, 128 & 256 filters) and *AveragePooling2D* layers,\n",
    "    - a *GlobalAveragePooling2D* layer,\n",
    "    - 1 *Dense* layer with 132 nodes, and\n",
    "    - an output *Dense* layer with 7 nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "io9rnPUceyKx"
   },
   "source": [
    "# Mount Google Drive & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ndBDuhivUu7C",
    "outputId": "f196c6b3-ca13-474f-d1f0-2f7c44b62ee7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#@title Mount Google Drive {display-mode: \"form\"}\n",
    "\n",
    "# This code will be hidden when the notebook is loaded.\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_kTFrNNPU7wP"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "import time\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "\n",
    "# Setting random seeds to reduce the amount of randomness in the neural net weights and results\n",
    "# The results may still not be exactly reproducible\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 201
    },
    "id": "ggkatHAQU75X",
    "outputId": "205fdc6d-9d0b-4adf-c3c2-1e180bd8550a"
   },
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "GPU device not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m device_name \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mtest\u001b[38;5;241m.\u001b[39mgpu_device_name()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device_name \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/device:GPU:0\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mSystemError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGPU device not found\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFound GPU at: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(device_name))\n",
      "\u001b[1;31mSystemError\u001b[0m: GPU device not found"
     ]
    }
   ],
   "source": [
    "#@title Check for GPU\n",
    "\n",
    "# Testing to ensure GPU is being utilized\n",
    "# Ensure that the Runtime Type for this notebook is set to GPU\n",
    "# If a GPU device is not found, change the runtime type under: Runtime>> Change runtime type>> Hardware accelerator>> GPU\n",
    "# and run the notebook from the beginning again.\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xmhd2RT_fIaS"
   },
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5P0vu49KbWXH"
   },
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tCN57I6AU7_g",
    "outputId": "30c6ae8e-973f-43b8-f38a-ef238c838cbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done unzipping combined_faces.zip\n"
     ]
    }
   ],
   "source": [
    "# Unzipping the dataset file combined_faces.zip\n",
    "\n",
    "combined_faces_zip_path = \"combined_faces.zip\"\n",
    "\n",
    "with ZipFile(combined_faces_zip_path, 'r') as myzip:\n",
    "    myzip.extractall()\n",
    "    print('Done unzipping combined_faces.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "q61d9-wxU8Ea",
    "outputId": "042b3ce4-8408-4c2e-cb96-d213a4396707"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done unzipping combined_faces_train_augmented.zip\n"
     ]
    }
   ],
   "source": [
    "# Unzipping the dataset file combined_faces.zip\n",
    "\n",
    "combined_faces_zip_path = \"combined_faces_train_augmented (1).zip\"\n",
    "\n",
    "with ZipFile(combined_faces_zip_path, 'r') as myzip:\n",
    "    myzip.extractall()\n",
    "    print('Done unzipping combined_faces_train_augmented.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Yu50xj5jU8I6"
   },
   "outputs": [],
   "source": [
    "# Importing the augmented training dataset and testing dataset to create tensors of images using the filename paths.\n",
    "\n",
    "train_aug_df = pd.read_csv(\"images_filenames_labels_test.csv\")\n",
    "test_df = pd.read_csv(\"images_filenames_labels_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6lsicAOcbYZ"
   },
   "source": [
    "## Know your Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "80VuyS3lOZub",
    "outputId": "9c623966-6997-4732-ae69-e3e43107badb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/content/content/combined_faces/8_163.jpg</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/content/content/combined_faces/38_66.jpg</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/content/content/combined_faces/40_177.jpg</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/content/content/combined_faces/36_267.jpg</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/content/content/combined_faces/8_349.jpg</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     filename  age\n",
       "0   /content/content/combined_faces/8_163.jpg    8\n",
       "1   /content/content/combined_faces/38_66.jpg   38\n",
       "2  /content/content/combined_faces/40_177.jpg   40\n",
       "3  /content/content/combined_faces/36_267.jpg   36\n",
       "4   /content/content/combined_faces/8_349.jpg    8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_aug_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "EBcZJQchO-JH",
    "outputId": "3213d43c-7172-4bb9-c202-4a83976f6c24"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/content/content/combined_faces/8_163.jpg</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/content/content/combined_faces/38_66.jpg</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/content/content/combined_faces/40_177.jpg</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/content/content/combined_faces/36_267.jpg</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/content/content/combined_faces/8_349.jpg</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     filename  age\n",
       "0   /content/content/combined_faces/8_163.jpg    8\n",
       "1   /content/content/combined_faces/38_66.jpg   38\n",
       "2  /content/content/combined_faces/40_177.jpg   40\n",
       "3  /content/content/combined_faces/36_267.jpg   36\n",
       "4   /content/content/combined_faces/8_349.jpg    8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "5D3RBtwwU8W1",
    "outputId": "68f3d195-8297-4264-da65-15d28ab626ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10046, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_aug_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "J4Qz1-9mU8bN",
    "outputId": "c6fba137-60f5-42f2-a2bb-5acc2f72c9c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10046, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BT0E02E3cipb"
   },
   "source": [
    "## Define Age Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "QqlcD7x6Yjcd"
   },
   "outputs": [],
   "source": [
    "# Defining a function to return the class labels corresponding to the re-distributed 7 age-ranges.\n",
    "\n",
    "def class_labels_reassign(age):\n",
    "\n",
    "    if 1 <= age <= 2:\n",
    "        return 0\n",
    "    elif 3 <= age <= 9:\n",
    "        return 1\n",
    "    elif 10 <= age <= 20:\n",
    "        return 2\n",
    "    elif 21 <= age <= 27:\n",
    "        return 3\n",
    "    elif 28 <= age <= 45:\n",
    "        return 4\n",
    "    elif 46 <= age <= 65:\n",
    "        return 5\n",
    "    else:\n",
    "        return 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "LROsGcIaYjVr"
   },
   "outputs": [],
   "source": [
    "train_aug_df['target'] = train_aug_df['age'].map(class_labels_reassign)\n",
    "test_df['target'] = test_df['age'].map(class_labels_reassign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "j51hK9VIaxo1",
    "outputId": "1650c2fe-32bc-45ec-89ea-4e404aa66005"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>age</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/content/content/combined_faces/8_163.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/content/content/combined_faces/38_66.jpg</td>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/content/content/combined_faces/40_177.jpg</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/content/content/combined_faces/36_267.jpg</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/content/content/combined_faces/8_349.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     filename  age  target\n",
       "0   /content/content/combined_faces/8_163.jpg    8       1\n",
       "1   /content/content/combined_faces/38_66.jpg   38       4\n",
       "2  /content/content/combined_faces/40_177.jpg   40       4\n",
       "3  /content/content/combined_faces/36_267.jpg   36       4\n",
       "4   /content/content/combined_faces/8_349.jpg    8       1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_aug_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "csZb53SYaxgu",
    "outputId": "51bce903-897a-46af-fdee-5d2ac2df487c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>age</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/content/content/combined_faces/8_163.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/content/content/combined_faces/38_66.jpg</td>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/content/content/combined_faces/40_177.jpg</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/content/content/combined_faces/36_267.jpg</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/content/content/combined_faces/8_349.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     filename  age  target\n",
       "0   /content/content/combined_faces/8_163.jpg    8       1\n",
       "1   /content/content/combined_faces/38_66.jpg   38       4\n",
       "2  /content/content/combined_faces/40_177.jpg   40       4\n",
       "3  /content/content/combined_faces/36_267.jpg   36       4\n",
       "4   /content/content/combined_faces/8_349.jpg    8       1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s52pb794dHhn"
   },
   "source": [
    "## Organize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "sJSY34ShavL_"
   },
   "outputs": [],
   "source": [
    "# Converting the filenames and target class labels into lists for augmented train and test datasets.\n",
    "\n",
    "train_aug_filenames_list = list(train_aug_df['filename'])\n",
    "train_aug_labels_list = list(train_aug_df['target'])\n",
    "\n",
    "test_filenames_list = list(test_df['filename'])\n",
    "test_labels_list = list(test_df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "S7ye8s5savP5"
   },
   "outputs": [],
   "source": [
    "# Creating tensorflow constants of filenames and labels for augmented train and test datasets from the lists defined above.\n",
    "\n",
    "train_aug_filenames_tensor = tf.constant(train_aug_filenames_list)\n",
    "train_aug_labels_tensor = tf.constant(train_aug_labels_list)\n",
    "\n",
    "test_filenames_tensor = tf.constant(test_filenames_list)\n",
    "test_labels_tensor = tf.constant(test_labels_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FIUoR5YidZMA"
   },
   "source": [
    "# Image Greyscale Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "4ALPko3Xavbo"
   },
   "outputs": [],
   "source": [
    "# Defining a function to read the image, decode the image from given tensor and one-hot encode the image label class.\n",
    "# Changing the channels para in tf.io.decode_jpeg from 3 to 1 changes the output images from RGB coloured to grayscale.\n",
    "\n",
    "num_classes = 7\n",
    "\n",
    "def _parse_function(filename, label):\n",
    "\n",
    "    image_string = tf.io.read_file(filename)\n",
    "    image_decoded = tf.io.decode_jpeg(image_string, channels=1)    # channels=1 to convert to grayscale, channels=3 to convert to RGB.\n",
    "    # image_resized = tf.image.resize(image_decoded, [200, 200])\n",
    "    label = tf.one_hot(label, num_classes)\n",
    "\n",
    "    return image_decoded, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "OTyXZ2tUavZh"
   },
   "outputs": [],
   "source": [
    "# Getting the dataset ready for the neural network.\n",
    "# Using the tensor vectors defined above, accessing the images in the dataset and passing them through the function defined above.\n",
    "\n",
    "train_aug_dataset = tf.data.Dataset.from_tensor_slices((train_aug_filenames_tensor, train_aug_labels_tensor))\n",
    "train_aug_dataset = train_aug_dataset.map(_parse_function)\n",
    "# train_aug_dataset = train_aug_dataset.repeat(3)\n",
    "train_aug_dataset = train_aug_dataset.batch(512)    # Same as batch_size hyperparameter in model.fit() below.\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_filenames_tensor, test_labels_tensor))\n",
    "test_dataset = test_dataset.map(_parse_function)\n",
    "# test_dataset = test_dataset.repeat(3)\n",
    "test_dataset = test_dataset.batch(512)    # Same as batch_size hyperparameter in model.fit() below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TSLahA9adp-o"
   },
   "source": [
    "# CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 601
    },
    "id": "kcW44JspavWb",
    "outputId": "a0422f28-b465-48e7-f689-1a881ce61be5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BHUMI\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ average_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">97</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">97</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ average_pooling2d_1                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                   │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ average_pooling2d_2                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                   │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ average_pooling2d_3                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                   │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">33,924</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">931</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m198\u001b[0m, \u001b[38;5;34m198\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m320\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ average_pooling2d (\u001b[38;5;33mAveragePooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m97\u001b[0m, \u001b[38;5;34m97\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ average_pooling2d_1                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)                   │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ average_pooling2d_2                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)                   │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m295,168\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ average_pooling2d_3                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)                   │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m132\u001b[0m)                 │          \u001b[38;5;34m33,924\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)                   │             \u001b[38;5;34m931\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">422,695</span> (1.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m422,695\u001b[0m (1.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">422,695</span> (1.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m422,695\u001b[0m (1.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Defining the architecture of the sequential neural network.\n",
    "\n",
    "final_cnn = Sequential()\n",
    "\n",
    "# Input layer with 32 filters, followed by an AveragePooling2D layer.\n",
    "final_cnn.add(Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=(200, 200, 1)))    # 3rd dim = 1 for grayscale images.\n",
    "final_cnn.add(AveragePooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Three Conv2D layers with filters increasing by a factor of 2 for every successive Conv2D layer.\n",
    "final_cnn.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "final_cnn.add(AveragePooling2D(pool_size=(2,2)))\n",
    "\n",
    "final_cnn.add(Conv2D(filters=128, kernel_size=3, activation='relu'))\n",
    "final_cnn.add(AveragePooling2D(pool_size=(2,2)))\n",
    "\n",
    "final_cnn.add(Conv2D(filters=256, kernel_size=3, activation='relu'))\n",
    "final_cnn.add(AveragePooling2D(pool_size=(2,2)))\n",
    "\n",
    "# A GlobalAveragePooling2D layer before going into Dense layers below.\n",
    "# GlobalAveragePooling2D layer gives no. of outputs equal to no. of filters in last Conv2D layer above (256).\n",
    "final_cnn.add(GlobalAveragePooling2D())\n",
    "\n",
    "# One Dense layer with 132 nodes so as to taper down the no. of nodes from no. of outputs of GlobalAveragePooling2D layer above towards no. of nodes in output layer below (7).\n",
    "final_cnn.add(Dense(132, activation='relu'))\n",
    "\n",
    "# Output layer with 7 nodes (equal to the no. of classes).\n",
    "final_cnn.add(Dense(7, activation='softmax'))\n",
    "\n",
    "final_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "uBG5MY8zavTn"
   },
   "outputs": [],
   "source": [
    "# Compiling the above created CNN architecture.\n",
    "\n",
    "final_cnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "nWy7fRfHfu8L"
   },
   "outputs": [],
   "source": [
    "# Creating a TensorBoard callback object and saving it at the desired location.\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=f\"/content/drive/MyDrive/1.1_age_input_output/output/cnn_logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3pKfqLLbS3ld"
   },
   "source": [
    "We shall also use ***ModelCheckpoint*** as a callback while training the final CNN model so as to be able to save the model as it continues training and improving in performance over 60 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "X6dQDDhmfuzo"
   },
   "outputs": [],
   "source": [
    "# Creating a ModelCheckpoint callback object to save the model according to the value of val_accuracy.\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=f\"/content/drive/MyDrive/1.1_age_input_output/outputt/cnn_logs/age_model_checkpoint.keras\",\n",
    "                             monitor='val_accuracy',\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=False,\n",
    "                             verbose=1\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jxVlNLLMeLWw"
   },
   "source": [
    "# Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hU4LJT6xYjJp",
    "outputId": "9baa2bee-be55-4a01-fb49-9f23e9cdca15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Graph execution error:\n\nDetected at node ReadFile defined at (most recent call last):\n<stack traces unavailable>\nNewRandomAccessFile failed to Create/Open: /content/content/combined_faces/8_163.jpg : The system cannot find the path specified.\r\n; No such process\n\t [[{{node ReadFile}}]]\n\t [[IteratorGetNext]] [Op:__inference_one_step_on_iterator_2398]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Fitting the above created CNN model.\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m final_cnn_history \u001b[38;5;241m=\u001b[39m final_cnn\u001b[38;5;241m.\u001b[39mfit(train_aug_dataset,\n\u001b[0;32m      4\u001b[0m                                   batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m,\n\u001b[0;32m      5\u001b[0m                                   validation_data\u001b[38;5;241m=\u001b[39mtest_dataset,\n\u001b[0;32m      6\u001b[0m                                   epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m,\n\u001b[0;32m      7\u001b[0m                                   callbacks\u001b[38;5;241m=\u001b[39m[tensorboard, checkpoint],\n\u001b[0;32m      8\u001b[0m                                   shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m    \u001b[38;5;66;03m# shuffle=False to reduce randomness and increase reproducibility\u001b[39;00m\n\u001b[0;32m      9\u001b[0m                                  )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Graph execution error:\n\nDetected at node ReadFile defined at (most recent call last):\n<stack traces unavailable>\nNewRandomAccessFile failed to Create/Open: /content/content/combined_faces/8_163.jpg : The system cannot find the path specified.\r\n; No such process\n\t [[{{node ReadFile}}]]\n\t [[IteratorGetNext]] [Op:__inference_one_step_on_iterator_2398]"
     ]
    }
   ],
   "source": [
    "# Fitting the above created CNN model.\n",
    "\n",
    "final_cnn_history = final_cnn.fit(train_aug_dataset,\n",
    "                                  batch_size=512,\n",
    "                                  validation_data=test_dataset,\n",
    "                                  epochs=60,\n",
    "                                  callbacks=[tensorboard, checkpoint],\n",
    "                                  shuffle=False    # shuffle=False to reduce randomness and increase reproducibility\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "siwy6UeOavHB"
   },
   "source": [
    "# Checking Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "RP7vxY_6YjCM"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_cnn_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Checking the train and test loss and accuracy values from the neural network above.\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m final_cnn_history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      4\u001b[0m test_loss \u001b[38;5;241m=\u001b[39m final_cnn_history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      5\u001b[0m train_accuracy \u001b[38;5;241m=\u001b[39m final_cnn_history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'final_cnn_history' is not defined"
     ]
    }
   ],
   "source": [
    "# Checking the train and test loss and accuracy values from the neural network above.\n",
    "\n",
    "train_loss = final_cnn_history.history['loss']\n",
    "test_loss = final_cnn_history.history['val_loss']\n",
    "train_accuracy = final_cnn_history.history['accuracy']\n",
    "test_accuracy = final_cnn_history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "id": "COkki9JUU8kf",
    "outputId": "fd227df4-734f-41cd-979b-36ac79375bfb"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(ncols\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m,\u001b[38;5;241m7\u001b[39m))\n\u001b[0;32m      5\u001b[0m ax \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39mravel()\n\u001b[1;32m----> 7\u001b[0m ax[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mplot(train_loss, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Loss\u001b[39m\u001b[38;5;124m'\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroyalblue\u001b[39m\u001b[38;5;124m'\u001b[39m, marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m'\u001b[39m, markersize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m      8\u001b[0m ax[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mplot(test_loss, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Loss\u001b[39m\u001b[38;5;124m'\u001b[39m, color \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124morangered\u001b[39m\u001b[38;5;124m'\u001b[39m, marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m'\u001b[39m, markersize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m     10\u001b[0m ax[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mset_xlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpochs\u001b[39m\u001b[38;5;124m'\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m14\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_loss' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABMkAAAJMCAYAAADg/fHFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAoHklEQVR4nO3df2zV9b348Veh0Kr3toswKwiysqt3bGTuUgIDLlm2qzVo3OVmN7J4I+rVZM22i9CrdzBudBCTZruZuXMT3CZolqCX+DP+0etssnsRhfsDbjHLIHERroWtlRRji7pbBD7fP7z0e7sW5ZT+9PV4JOeP8/Hz6Xl37wGvPM+vsqIoigAAAACAxCaM9gIAAAAAYLSJZAAAAACkJ5IBAAAAkJ5IBgAAAEB6IhkAAAAA6YlkAAAAAKQnkgEAAACQnkgGAAAAQHoiGQAAAADpiWQAAAAApFdyJHvxxRfjhhtuiOnTp0dZWVk8++yzH3rNjh07oq6uLiorK2P27Nnx0EMPDWatAAAMI3MeAJBZyZHsnXfeiauuuip+9KMfndP5hw4diuuuuy6WLl0ara2t8e1vfztWrVoVTz31VMmLBQBg+JjzAIDMyoqiKAZ9cVlZPPPMM7F8+fKznvOtb30rnnvuuThw4EDvsYaGhnjllVdi9+7dg31oAACGkTkPAMimfLgfYPfu3VFfX9/n2LXXXhtbtmyJ9957LyZNmtTvmp6enujp6em9f/r06XjzzTdjypQpUVZWNtxLBgA+AoqiiOPHj8f06dNjwgQfwzoczHkAwGgYrjlv2CNZR0dH1NTU9DlWU1MTJ0+ejM7Ozpg2bVq/a5qammLDhg3DvTQAIIHDhw/HjBkzRnsZH0nmPABgNA31nDfskSwi+j0reOYdnmd7tnDdunXR2NjYe7+rqysuv/zyOHz4cFRVVQ3fQgGAj4zu7u6YOXNm/OEf/uFoL+UjzZwHAIy04Zrzhj2SXXrppdHR0dHn2NGjR6O8vDymTJky4DUVFRVRUVHR73hVVZXhCQAoibfwDR9zHgAwmoZ6zhv2D+hYtGhRtLS09Dn2wgsvxPz58wf8nAoAAMYHcx4A8FFSciR7++23Y9++fbFv376IeP+rv/ft2xdtbW0R8f5L6FeuXNl7fkNDQ7z++uvR2NgYBw4ciK1bt8aWLVvirrvuGprfAACAIWHOAwAyK/ntlnv27IkvfvGLvffPfKbELbfcEo8++mi0t7f3DlIREbW1tdHc3Bxr1qyJBx98MKZPnx4PPPBAfOUrXxmC5QMAMFTMeQBAZmXFmU9XHcO6u7ujuro6urq6fFYFAHBOzA/jg30CAEo1XPPDsH8mGQAAAACMdSIZAAAAAOmJZAAAAACkJ5IBAAAAkJ5IBgAAAEB6IhkAAAAA6YlkAAAAAKQnkgEAAACQnkgGAAAAQHoiGQAAAADpiWQAAAAApCeSAQAAAJCeSAYAAABAeiIZAAAAAOmJZAAAAACkJ5IBAAAAkJ5IBgAAAEB6IhkAAAAA6YlkAAAAAKQnkgEAAACQnkgGAAAAQHoiGQAAAADpiWQAAAAApCeSAQAAAJCeSAYAAABAeiIZAAAAAOmJZAAAAACkJ5IBAAAAkJ5IBgAAAEB6IhkAAAAA6YlkAAAAAKQnkgEAAACQnkgGAAAAQHoiGQAAAADpiWQAAAAApCeSAQAAAJCeSAYAAABAeiIZAAAAAOmJZAAAAACkJ5IBAAAAkJ5IBgAAAEB6IhkAAAAA6YlkAAAAAKQnkgEAAACQnkgGAAAAQHoiGQAAAADpiWQAAAAApCeSAQAAAJCeSAYAAABAeiIZAAAAAOmJZAAAAACkJ5IBAAAAkJ5IBgAAAEB6IhkAAAAA6YlkAAAAAKQnkgEAAACQnkgGAAAAQHoiGQAAAADpiWQAAAAApCeSAQAAAJCeSAYAAABAeiIZAAAAAOmJZAAAAACkJ5IBAAAAkJ5IBgAAAEB6IhkAAAAA6YlkAAAAAKQnkgEAAACQnkgGAAAAQHoiGQAAAADpiWQAAAAApCeSAQAAAJCeSAYAAABAeiIZAAAAAOmJZAAAAACkJ5IBAAAAkJ5IBgAAAEB6IhkAAAAA6YlkAAAAAKQnkgEAAACQnkgGAAAAQHoiGQAAAADpiWQAAAAApCeSAQAAAJCeSAYAAABAeiIZAAAAAOmJZAAAAACkJ5IBAAAAkJ5IBgAAAEB6IhkAAAAA6YlkAAAAAKQnkgEAAACQnkgGAAAAQHoiGQAAAADpiWQAAAAApCeSAQAAAJCeSAYAAABAeoOKZJs2bYra2tqorKyMurq62Llz5weev23btrjqqqviwgsvjGnTpsVtt90Wx44dG9SCAQAYPuY8ACCrkiPZ9u3bY/Xq1bF+/fpobW2NpUuXxrJly6KtrW3A81966aVYuXJl3H777fGrX/0qnnjiifjP//zPuOOOO8578QAADB1zHgCQWcmR7P7774/bb7897rjjjpgzZ0784z/+Y8ycOTM2b9484Pn/9m//Fp/4xCdi1apVUVtbG3/6p38aX/va12LPnj3nvXgAAIaOOQ8AyKykSHbixInYu3dv1NfX9zleX18fu3btGvCaxYsXx5EjR6K5uTmKoog33ngjnnzyybj++uvP+jg9PT3R3d3d5wYAwPAx5wEA2ZUUyTo7O+PUqVNRU1PT53hNTU10dHQMeM3ixYtj27ZtsWLFipg8eXJceuml8bGPfSx++MMfnvVxmpqaorq6uvc2c+bMUpYJAECJzHkAQHaD+uD+srKyPveLouh37Iz9+/fHqlWr4p577om9e/fG888/H4cOHYqGhoaz/vx169ZFV1dX7+3w4cODWSYAACUy5wEAWZWXcvLUqVNj4sSJ/Z5NPHr0aL9nHc9oamqKJUuWxN133x0REZ/97GfjoosuiqVLl8Z9990X06ZN63dNRUVFVFRUlLI0AADOgzkPAMiupFeSTZ48Oerq6qKlpaXP8ZaWlli8ePGA17z77rsxYULfh5k4cWJEvP/MJAAAo8+cBwBkV/LbLRsbG+Phhx+OrVu3xoEDB2LNmjXR1tbW+7L6devWxcqVK3vPv+GGG+Lpp5+OzZs3x8GDB+Pll1+OVatWxYIFC2L69OlD95sAAHBezHkAQGYlvd0yImLFihVx7Nix2LhxY7S3t8fcuXOjubk5Zs2aFRER7e3t0dbW1nv+rbfeGsePH48f/ehH8bd/+7fxsY99LL70pS/Fd7/73aH7LQAAOG/mPAAgs7JiHLwWvru7O6qrq6OrqyuqqqpGezkAwDhgfhgf7BMAUKrhmh8G9e2WAAAAAPBRIpIBAAAAkJ5IBgAAAEB6IhkAAAAA6YlkAAAAAKQnkgEAAACQnkgGAAAAQHoiGQAAAADpiWQAAAAApCeSAQAAAJCeSAYAAABAeiIZAAAAAOmJZAAAAACkJ5IBAAAAkJ5IBgAAAEB6IhkAAAAA6YlkAAAAAKQnkgEAAACQnkgGAAAAQHoiGQAAAADpiWQAAAAApCeSAQAAAJCeSAYAAABAeiIZAAAAAOmJZAAAAACkJ5IBAAAAkJ5IBgAAAEB6IhkAAAAA6YlkAAAAAKQnkgEAAACQnkgGAAAAQHoiGQAAAADpiWQAAAAApCeSAQAAAJCeSAYAAABAeiIZAAAAAOmJZAAAAACkJ5IBAAAAkJ5IBgAAAEB6IhkAAAAA6YlkAAAAAKQnkgEAAACQnkgGAAAAQHoiGQAAAADpiWQAAAAApCeSAQAAAJCeSAYAAABAeiIZAAAAAOmJZAAAAACkJ5IBAAAAkJ5IBgAAAEB6IhkAAAAA6YlkAAAAAKQnkgEAAACQnkgGAAAAQHoiGQAAAADpiWQAAAAApCeSAQAAAJCeSAYAAABAeiIZAAAAAOmJZAAAAACkJ5IBAAAAkJ5IBgAAAEB6IhkAAAAA6YlkAAAAAKQnkgEAAACQnkgGAAAAQHoiGQAAAADpiWQAAAAApCeSAQAAAJCeSAYAAABAeiIZAAAAAOmJZAAAAACkJ5IBAAAAkJ5IBgAAAEB6IhkAAAAA6YlkAAAAAKQnkgEAAACQnkgGAAAAQHoiGQAAAADpiWQAAAAApCeSAQAAAJCeSAYAAABAeiIZAAAAAOmJZAAAAACkJ5IBAAAAkJ5IBgAAAEB6IhkAAAAA6YlkAAAAAKQnkgEAAACQnkgGAAAAQHoiGQAAAADpiWQAAAAApCeSAQAAAJCeSAYAAABAeiIZAAAAAOmJZAAAAACkN6hItmnTpqitrY3Kysqoq6uLnTt3fuD5PT09sX79+pg1a1ZUVFTEJz/5ydi6deugFgwAwPAx5wEAWZWXesH27dtj9erVsWnTpliyZEn8+Mc/jmXLlsX+/fvj8ssvH/CaG2+8Md54443YsmVL/NEf/VEcPXo0Tp48ed6LBwBg6JjzAIDMyoqiKEq5YOHChTFv3rzYvHlz77E5c+bE8uXLo6mpqd/5zz//fHz1q1+NgwcPxsUXXzyoRXZ3d0d1dXV0dXVFVVXVoH4GAJCL+aF05jwAYDwYrvmhpLdbnjhxIvbu3Rv19fV9jtfX18euXbsGvOa5556L+fPnx/e+97247LLL4sorr4y77rorfve73531cXp6eqK7u7vPDQCA4WPOAwCyK+ntlp2dnXHq1Kmoqanpc7ympiY6OjoGvObgwYPx0ksvRWVlZTzzzDPR2dkZX//61+PNN9886+dVNDU1xYYNG0pZGgAA58GcBwBkN6gP7i8rK+tzvyiKfsfOOH36dJSVlcW2bdtiwYIFcd1118X9998fjz766FmfZVy3bl10dXX13g4fPjyYZQIAUCJzHgCQVUmvJJs6dWpMnDix37OJR48e7fes4xnTpk2Lyy67LKqrq3uPzZkzJ4qiiCNHjsQVV1zR75qKioqoqKgoZWkAAJwHcx4AkF1JrySbPHly1NXVRUtLS5/jLS0tsXjx4gGvWbJkSfz2t7+Nt99+u/fYq6++GhMmTIgZM2YMYskAAAw1cx4AkF3Jb7dsbGyMhx9+OLZu3RoHDhyINWvWRFtbWzQ0NETE+y+hX7lyZe/5N910U0yZMiVuu+222L9/f7z44otx9913x1//9V/HBRdcMHS/CQAA58WcBwBkVtLbLSMiVqxYEceOHYuNGzdGe3t7zJ07N5qbm2PWrFkREdHe3h5tbW295//BH/xBtLS0xN/8zd/E/PnzY8qUKXHjjTfGfffdN3S/BQAA582cBwBkVlYURTHai/gw3d3dUV1dHV1dXVFVVTXaywEAxgHzw/hgnwCAUg3X/DCob7cEAAAAgI8SkQwAAACA9EQyAAAAANITyQAAAABITyQDAAAAID2RDAAAAID0RDIAAAAA0hPJAAAAAEhPJAMAAAAgPZEMAAAAgPREMgAAAADSE8kAAAAASE8kAwAAACA9kQwAAACA9EQyAAAAANITyQAAAABITyQDAAAAID2RDAAAAID0RDIAAAAA0hPJAAAAAEhPJAMAAAAgPZEMAAAAgPREMgAAAADSE8kAAAAASE8kAwAAACA9kQwAAACA9EQyAAAAANITyQAAAABITyQDAAAAID2RDAAAAID0RDIAAAAA0hPJAAAAAEhPJAMAAAAgPZEMAAAAgPREMgAAAADSE8kAAAAASE8kAwAAACA9kQwAAACA9EQyAAAAANITyQAAAABITyQDAAAAID2RDAAAAID0RDIAAAAA0hPJAAAAAEhPJAMAAAAgPZEMAAAAgPREMgAAAADSE8kAAAAASE8kAwAAACA9kQwAAACA9EQyAAAAANITyQAAAABITyQDAAAAID2RDAAAAID0RDIAAAAA0hPJAAAAAEhPJAMAAAAgPZEMAAAAgPREMgAAAADSE8kAAAAASE8kAwAAACA9kQwAAACA9EQyAAAAANITyQAAAABITyQDAAAAID2RDAAAAID0RDIAAAAA0hPJAAAAAEhPJAMAAAAgPZEMAAAAgPREMgAAAADSE8kAAAAASE8kAwAAACA9kQwAAACA9EQyAAAAANITyQAAAABITyQDAAAAID2RDAAAAID0RDIAAAAA0hPJAAAAAEhPJAMAAAAgPZEMAAAAgPREMgAAAADSE8kAAAAASE8kAwAAACA9kQwAAACA9EQyAAAAANITyQAAAABITyQDAAAAID2RDAAAAID0RDIAAAAA0hPJAAAAAEhPJAMAAAAgPZEMAAAAgPREMgAAAADSE8kAAAAASG9QkWzTpk1RW1sblZWVUVdXFzt37jyn615++eUoLy+Pz33uc4N5WAAAhpk5DwDIquRItn379li9enWsX78+WltbY+nSpbFs2bJoa2v7wOu6urpi5cqV8Wd/9meDXiwAAMPHnAcAZFZWFEVRygULFy6MefPmxebNm3uPzZkzJ5YvXx5NTU1nve6rX/1qXHHFFTFx4sR49tlnY9++fef8mN3d3VFdXR1dXV1RVVVVynIBgKTMD6Uz5wEA48FwzQ8lvZLsxIkTsXfv3qivr+9zvL6+Pnbt2nXW6x555JF47bXX4t577x3cKgEAGFbmPAAgu/JSTu7s7IxTp05FTU1Nn+M1NTXR0dEx4DW//vWvY+3atbFz584oLz+3h+vp6Ymenp7e+93d3aUsEwCAEpnzAIDsBvXB/WVlZX3uF0XR71hExKlTp+Kmm26KDRs2xJVXXnnOP7+pqSmqq6t7bzNnzhzMMgEAKJE5DwDIqqRINnXq1Jg4cWK/ZxOPHj3a71nHiIjjx4/Hnj174pvf/GaUl5dHeXl5bNy4MV555ZUoLy+PX/ziFwM+zrp166Krq6v3dvjw4VKWCQBAicx5AEB2Jb3dcvLkyVFXVxctLS3xF3/xF73HW1pa4s///M/7nV9VVRW//OUv+xzbtGlT/OIXv4gnn3wyamtrB3ycioqKqKioKGVpAACcB3MeAJBdSZEsIqKxsTFuvvnmmD9/fixatCh+8pOfRFtbWzQ0NETE+88O/uY3v4mf/exnMWHChJg7d26f6y+55JKorKzsdxwAgNFlzgMAMis5kq1YsSKOHTsWGzdujPb29pg7d240NzfHrFmzIiKivb092trahnyhAAAML3MeAJBZWVEUxWgv4sN0d3dHdXV1dHV1RVVV1WgvBwAYB8wP44N9AgBKNVzzw6C+3RIAAAAAPkpEMgAAAADSE8kAAAAASE8kAwAAACA9kQwAAACA9EQyAAAAANITyQAAAABITyQDAAAAID2RDAAAAID0RDIAAAAA0hPJAAAAAEhPJAMAAAAgPZEMAAAAgPREMgAAAADSE8kAAAAASE8kAwAAACA9kQwAAACA9EQyAAAAANITyQAAAABITyQDAAAAID2RDAAAAID0RDIAAAAA0hPJAAAAAEhPJAMAAAAgPZEMAAAAgPREMgAAAADSE8kAAAAASE8kAwAAACA9kQwAAACA9EQyAAAAANITyQAAAABITyQDAAAAID2RDAAAAID0RDIAAAAA0hPJAAAAAEhPJAMAAAAgPZEMAAAAgPREMgAAAADSE8kAAAAASE8kAwAAACA9kQwAAACA9EQyAAAAANITyQAAAABITyQDAAAAID2RDAAAAID0RDIAAAAA0hPJAAAAAEhPJAMAAAAgPZEMAAAAgPREMgAAAADSE8kAAAAASE8kAwAAACA9kQwAAACA9EQyAAAAANITyQAAAABITyQDAAAAID2RDAAAAID0RDIAAAAA0hPJAAAAAEhPJAMAAAAgPZEMAAAAgPREMgAAAADSE8kAAAAASE8kAwAAACA9kQwAAACA9EQyAAAAANITyQAAAABITyQDAAAAID2RDAAAAID0RDIAAAAA0hPJAAAAAEhPJAMAAAAgPZEMAAAAgPREMgAAAADSE8kAAAAASE8kAwAAACA9kQwAAACA9EQyAAAAANITyQAAAABITyQDAAAAID2RDAAAAID0RDIAAAAA0hPJAAAAAEhPJAMAAAAgPZEMAAAAgPREMgAAAADSE8kAAAAASE8kAwAAACA9kQwAAACA9EQyAAAAANITyQAAAABITyQDAAAAID2RDAAAAID0RDIAAAAA0hPJAAAAAEhPJAMAAAAgPZEMAAAAgPQGFck2bdoUtbW1UVlZGXV1dbFz586znvv000/HNddcEx//+MejqqoqFi1aFD//+c8HvWAAAIaPOQ8AyKrkSLZ9+/ZYvXp1rF+/PlpbW2Pp0qWxbNmyaGtrG/D8F198Ma655ppobm6OvXv3xhe/+MW44YYborW19bwXDwDA0DHnAQCZlRVFUZRywcKFC2PevHmxefPm3mNz5syJ5cuXR1NT0zn9jM985jOxYsWKuOeee87p/O7u7qiuro6urq6oqqoqZbkAQFLmh9KZ8wCA8WC45oeSXkl24sSJ2Lt3b9TX1/c5Xl9fH7t27Tqnn3H69Ok4fvx4XHzxxWc9p6enJ7q7u/vcAAAYPuY8ACC7kiJZZ2dnnDp1Kmpqavocr6mpiY6OjnP6Gd///vfjnXfeiRtvvPGs5zQ1NUV1dXXvbebMmaUsEwCAEpnzAIDsBvXB/WVlZX3uF0XR79hAHn/88fjOd74T27dvj0suueSs561bty66urp6b4cPHx7MMgEAKJE5DwDIqryUk6dOnRoTJ07s92zi0aNH+z3r+Pu2b98et99+ezzxxBNx9dVXf+C5FRUVUVFRUcrSAAA4D+Y8ACC7kl5JNnny5Kirq4uWlpY+x1taWmLx4sVnve7xxx+PW2+9NR577LG4/vrrB7dSAACGjTkPAMiupFeSRUQ0NjbGzTffHPPnz49FixbFT37yk2hra4uGhoaIeP8l9L/5zW/iZz/7WUS8PzitXLkyfvCDH8TnP//53mcnL7jggqiurh7CXwUAgPNhzgMAMis5kq1YsSKOHTsWGzdujPb29pg7d240NzfHrFmzIiKivb092traes//8Y9/HCdPnoxvfOMb8Y1vfKP3+C233BKPPvro+f8GAAAMCXMeAJBZWVEUxWgv4sN0d3dHdXV1dHV1RVVV1WgvBwAYB8wP44N9AgBKNVzzw6C+3RIAAAAAPkpEMgAAAADSE8kAAAAASE8kAwAAACA9kQwAAACA9EQyAAAAANITyQAAAABITyQDAAAAID2RDAAAAID0RDIAAAAA0hPJAAAAAEhPJAMAAAAgPZEMAAAAgPREMgAAAADSE8kAAAAASE8kAwAAACA9kQwAAACA9EQyAAAAANITyQAAAABITyQDAAAAID2RDAAAAID0RDIAAAAA0hPJAAAAAEhPJAMAAAAgPZEMAAAAgPREMgAAAADSE8kAAAAASE8kAwAAACA9kQwAAACA9EQyAAAAANITyQAAAABITyQDAAAAID2RDAAAAID0RDIAAAAA0hPJAAAAAEhPJAMAAAAgPZEMAAAAgPREMgAAAADSE8kAAAAASE8kAwAAACA9kQwAAACA9EQyAAAAANITyQAAAABITyQDAAAAID2RDAAAAID0RDIAAAAA0hPJAAAAAEhPJAMAAAAgPZEMAAAAgPREMgAAAADSE8kAAAAASE8kAwAAACA9kQwAAACA9EQyAAAAANITyQAAAABITyQDAAAAID2RDAAAAID0RDIAAAAA0hPJAAAAAEhPJAMAAAAgPZEMAAAAgPREMgAAAADSE8kAAAAASE8kAwAAACA9kQwAAACA9EQyAAAAANITyQAAAABITyQDAAAAID2RDAAAAID0RDIAAAAA0hPJAAAAAEhPJAMAAAAgPZEMAAAAgPREMgAAAADSE8kAAAAASE8kAwAAACA9kQwAAACA9EQyAAAAANITyQAAAABITyQDAAAAID2RDAAAAID0RDIAAAAA0hPJAAAAAEhPJAMAAAAgPZEMAAAAgPREMgAAAADSE8kAAAAASE8kAwAAACA9kQwAAACA9EQyAAAAANITyQAAAABITyQDAAAAID2RDAAAAID0RDIAAAAA0hPJAAAAAEhPJAMAAAAgPZEMAAAAgPQGFck2bdoUtbW1UVlZGXV1dbFz584PPH/Hjh1RV1cXlZWVMXv27HjooYcGtVgAAIaXOQ8AyKrkSLZ9+/ZYvXp1rF+/PlpbW2Pp0qWxbNmyaGtrG/D8Q4cOxXXXXRdLly6N1tbW+Pa3vx2rVq2Kp5566rwXDwDA0DHnAQCZlRVFUZRywcKFC2PevHmxefPm3mNz5syJ5cuXR1NTU7/zv/Wtb8Vzzz0XBw4c6D3W0NAQr7zySuzevfucHrO7uzuqq6ujq6srqqqqSlkuAJCU+aF05jwAYDwYrvmhvJSTT5w4EXv37o21a9f2OV5fXx+7du0a8Jrdu3dHfX19n2PXXnttbNmyJd57772YNGlSv2t6enqip6en935XV1dEvP8/AgDAuTgzN5T4fGBa5jwAYLwYrjmvpEjW2dkZp06dipqamj7Ha2pqoqOjY8BrOjo6Bjz/5MmT0dnZGdOmTet3TVNTU2zYsKHf8ZkzZ5ayXACAOHbsWFRXV4/2MsY8cx4AMN4M9ZxXUiQ7o6ysrM/9oij6Hfuw8wc6fsa6deuisbGx9/5bb70Vs2bNira2NkPuGNbd3R0zZ86Mw4cPe7vEGGWPxgf7ND7Yp7Gvq6srLr/88rj44otHeynjijmPgfg7b+yzR+ODfRof7NPYN1xzXkmRbOrUqTFx4sR+zyYePXq037OIZ1x66aUDnl9eXh5TpkwZ8JqKioqoqKjod7y6utr/QceBqqoq+zTG2aPxwT6ND/Zp7JswYVBf5p2OOY9z4e+8sc8ejQ/2aXywT2PfUM95Jf20yZMnR11dXbS0tPQ53tLSEosXLx7wmkWLFvU7/4UXXoj58+cP+DkVAACMPHMeAJBdycmtsbExHn744di6dWscOHAg1qxZE21tbdHQ0BAR77+EfuXKlb3nNzQ0xOuvvx6NjY1x4MCB2Lp1a2zZsiXuuuuuofstAAA4b+Y8ACCzkj+TbMWKFXHs2LHYuHFjtLe3x9y5c6O5uTlmzZoVERHt7e3R1tbWe35tbW00NzfHmjVr4sEHH4zp06fHAw88EF/5ylfO+TErKiri3nvvHfCl+Ywd9mnss0fjg30aH+zT2GePSmfO42zs09hnj8YH+zQ+2Kexb7j2qKzwvegAAAAAJOeTbAEAAABITyQDAAAAID2RDAAAAID0RDIAAAAA0hszkWzTpk1RW1sblZWVUVdXFzt37vzA83fs2BF1dXVRWVkZs2fPjoceemiEVppXKXv09NNPxzXXXBMf//jHo6qqKhYtWhQ///nPR3C1eZX6Z+mMl19+OcrLy+Nzn/vc8C6QiCh9n3p6emL9+vUxa9asqKioiE9+8pOxdevWEVptTqXu0bZt2+Kqq66KCy+8MKZNmxa33XZbHDt2bIRWm9OLL74YN9xwQ0yfPj3Kysri2Wef/dBrzA+jw5w39pnzxgdz3vhgzhv7zHlj36jNecUY8E//9E/FpEmTip/+9KfF/v37izvvvLO46KKLitdff33A8w8ePFhceOGFxZ133lns37+/+OlPf1pMmjSpePLJJ0d45XmUukd33nln8d3vfrf4j//4j+LVV18t1q1bV0yaNKn4r//6rxFeeS6l7tMZb731VjF79uyivr6+uOqqq0ZmsYkNZp++/OUvFwsXLixaWlqKQ4cOFf/+7/9evPzyyyO46lxK3aOdO3cWEyZMKH7wgx8UBw8eLHbu3Fl85jOfKZYvXz7CK8+lubm5WL9+ffHUU08VEVE888wzH3i++WF0mPPGPnPe+GDOGx/MeWOfOW98GK05b0xEsgULFhQNDQ19jn3qU58q1q5dO+D5f/d3f1d86lOf6nPsa1/7WvH5z39+2NaYXal7NJBPf/rTxYYNG4Z6afwfg92nFStWFH//939f3HvvvYanEVDqPv3zP/9zUV1dXRw7dmwklkdR+h79wz/8QzF79uw+xx544IFixowZw7ZG+jqX4cn8MDrMeWOfOW98MOeND+a8sc+cN/6M5Jw36m+3PHHiROzduzfq6+v7HK+vr49du3YNeM3u3bv7nX/ttdfGnj174r333hu2tWY1mD36fadPn47jx4/HxRdfPBxLJAa/T4888ki89tprce+99w73EonB7dNzzz0X8+fPj+9973tx2WWXxZVXXhl33XVX/O53vxuJJaczmD1avHhxHDlyJJqbm6MoinjjjTfiySefjOuvv34klsw5Mj+MPHPe2GfOGx/MeeODOW/sM+d9dA3V/FA+1AsrVWdnZ5w6dSpqamr6HK+pqYmOjo4Br+no6Bjw/JMnT0ZnZ2dMmzZt2Nab0WD26Pd9//vfj3feeSduvPHG4VgiMbh9+vWvfx1r166NnTt3Rnn5qP91kMJg9ungwYPx0ksvRWVlZTzzzDPR2dkZX//61+PNN9/0eRXDYDB7tHjx4ti2bVusWLEi/ud//idOnjwZX/7yl+OHP/zhSCyZc2R+GHnmvLHPnDc+mPPGB3Pe2GfO++gaqvlh1F9JdkZZWVmf+0VR9Dv2YecPdJyhU+oenfH444/Hd77zndi+fXtccsklw7U8/te57tOpU6fipptuig0bNsSVV145Usvjf5Xy5+n06dNRVlYW27ZtiwULFsR1110X999/fzz66KOeZRxGpezR/v37Y9WqVXHPPffE3r174/nnn49Dhw5FQ0PDSCyVEpgfRoc5b+wz540P5rzxwZw39pnzPpqGYn4Y9acUpk6dGhMnTuxXbY8ePdqvAp5x6aWXDnh+eXl5TJkyZdjWmtVg9uiM7du3x+233x5PPPFEXH311cO5zPRK3afjx4/Hnj17orW1Nb75zW9GxPv/SBdFEeXl5fHCCy/El770pRFZeyaD+fM0bdq0uOyyy6K6urr32Jw5c6Ioijhy5EhcccUVw7rmbAazR01NTbFkyZK4++67IyLis5/9bFx00UWxdOnSuO+++7zyZYwwP4w8c97YZ84bH8x544M5b+wz5310DdX8MOqvJJs8eXLU1dVFS0tLn+MtLS2xePHiAa9ZtGhRv/NfeOGFmD9/fkyaNGnY1prVYPYo4v1nFm+99dZ47LHHvF97BJS6T1VVVfHLX/4y9u3b13traGiIP/7jP459+/bFwoULR2rpqQzmz9OSJUvit7/9bbz99tu9x1599dWYMGFCzJgxY1jXm9Fg9ujdd9+NCRP6/pM6ceLEiPj/z2Ax+swPI8+cN/aZ88YHc974YM4b+8x5H11DNj+U9DH/w+TMV7Bu2bKl2L9/f7F69erioosuKv77v/+7KIqiWLt2bXHzzTf3nn/mqz3XrFlT7N+/v9iyZYuvBh9mpe7RY489VpSXlxcPPvhg0d7e3nt76623RutXSKHUffp9vvVoZJS6T8ePHy9mzJhR/OVf/mXxq1/9qtixY0dxxRVXFHfcccdo/QofeaXu0SOPPFKUl5cXmzZtKl577bXipZdeKubPn18sWLBgtH6FFI4fP160trYWra2tRUQU999/f9Ha2tr7Fe7mh7HBnDf2mfPGB3Pe+GDOG/vMeePDaM15YyKSFUVRPPjgg8WsWbOKyZMnF/PmzSt27NjR+99uueWW4gtf+EKf8//1X/+1+JM/+ZNi8uTJxSc+8Yli8+bNI7zifErZoy984QtFRPS73XLLLSO/8GRK/bP0fxmeRk6p+3TgwIHi6quvLi644IJixowZRWNjY/Huu++O8KpzKXWPHnjggeLTn/50ccEFFxTTpk0r/uqv/qo4cuTICK86l3/5l3/5wH9rzA9jhzlv7DPnjQ/mvPHBnDf2mfPGvtGa88qKwusDAQAAAMht1D+TDAAAAABGm0gGAAAAQHoiGQAAAADpiWQAAAAApCeSAQAAAJCeSAYAAABAeiIZAAAAAOmJZAAAAACkJ5IBAAAAkJ5IBgAAAEB6IhkAAAAA6YlkAAAAAKT3/wCz7pPogJxECAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1500x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting a line chart to visualize the loss and accuracy values by epochs.\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(15,7))\n",
    "\n",
    "ax = ax.ravel()\n",
    "\n",
    "ax[0].plot(train_loss, label='Train Loss', color='royalblue', marker='o', markersize=5)\n",
    "ax[0].plot(test_loss, label='Test Loss', color = 'orangered', marker='o', markersize=5)\n",
    "\n",
    "ax[0].set_xlabel('Epochs', fontsize=14)\n",
    "ax[0].set_ylabel('Categorical Crossentropy', fontsize=14)\n",
    "\n",
    "ax[0].legend(fontsize=14)\n",
    "ax[0].tick_params(axis='both', labelsize=12)\n",
    "\n",
    "ax[1].plot(train_accuracy, label='Train Accuracy', color='royalblue', marker='o', markersize=5)\n",
    "ax[1].plot(test_accuracy, label='Test Accuracy', color='orangered', marker='o', markersize=5)\n",
    "\n",
    "ax[1].set_xlabel('Epochs', fontsize=14)\n",
    "ax[1].set_ylabel('Accuracy', fontsize=14)\n",
    "\n",
    "ax[1].legend(fontsize=14)\n",
    "ax[1].tick_params(axis='both', labelsize=12)\n",
    "\n",
    "fig.suptitle(x=0.5, y=0.92, t=\"Lineplots showing loss and accuracy of CNN model by epochs\", fontsize=16)\n",
    "\n",
    "# Exporting plot image in PNG format.\n",
    "plt.savefig('/content/drive/MyDrive/1.1_age_input_output/output/cnn_logs/final_cnn_loss_accuracy.png', bbox_inches='tight');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F75NJtVJU8oD",
    "outputId": "ea038f01-1c6b-415f-cfb8-0682d98c46b1"
   },
   "outputs": [],
   "source": [
    "# Evaluating the model on test dataset.\n",
    "\n",
    "final_cnn_score = final_cnn.evaluate(test_dataset, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h5JdZYFMU8s0",
    "outputId": "0f1c3605-8bfa-4bdb-ff09-2d7fd847bb82"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_cnn_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Printing the relevant score summary.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m final_cnn_labels \u001b[38;5;241m=\u001b[39m final_cnn\u001b[38;5;241m.\u001b[39mmetrics_names\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCNN model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_cnn_labels[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m= \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(final_cnn_score[\u001b[38;5;241m0\u001b[39m],\u001b[38;5;250m \u001b[39m\u001b[38;5;241m3\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCNN model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_cnn_labels[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m= \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(final_cnn_score[\u001b[38;5;241m1\u001b[39m],\u001b[38;5;250m \u001b[39m\u001b[38;5;241m3\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'final_cnn_score' is not defined"
     ]
    }
   ],
   "source": [
    "# Printing the relevant score summary.\n",
    "\n",
    "final_cnn_labels = final_cnn.metrics_names\n",
    "print(f'CNN model {final_cnn_labels[0]} \\t\\t= {round(final_cnn_score[0], 3)}')\n",
    "print(f'CNN model {final_cnn_labels[1]} \\t= {round(final_cnn_score[1], 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "fatkGFAkrjCF"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_cnn_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Saving the model as a h5 file for possible use later.\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m final_cnn\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/drive/MyDrive/1.1_age_input_output/output/age_model_acc_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(final_cnn_score[\u001b[38;5;241m1\u001b[39m],\u001b[38;5;250m \u001b[39m\u001b[38;5;241m3\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, save_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'final_cnn_score' is not defined"
     ]
    }
   ],
   "source": [
    "# Saving the model as a h5 file for possible use later.\n",
    "\n",
    "final_cnn.save(f\"/content/drive/MyDrive/1.1_age_input_output/output/age_model_acc_{round(final_cnn_score[1], 3)}.h5\", save_format='h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EpFNy9QFe_pN"
   },
   "source": [
    "### Plotting Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "R1e1uYqHU8wx"
   },
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} NewRandomAccessFile failed to Create/Open: /content/content/combined_faces/8_163.jpg : The system cannot find the path specified.\r\n; No such process\n\t [[{{node ReadFile}}]] [Op:IteratorGetNext] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Generating predictions from the model above.\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m final_cnn_pred \u001b[38;5;241m=\u001b[39m final_cnn\u001b[38;5;241m.\u001b[39mpredict(test_dataset)\n\u001b[0;32m      4\u001b[0m final_cnn_pred \u001b[38;5;241m=\u001b[39m final_cnn_pred\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:6002\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6000\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[0;32m   6001\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m-> 6002\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} NewRandomAccessFile failed to Create/Open: /content/content/combined_faces/8_163.jpg : The system cannot find the path specified.\r\n; No such process\n\t [[{{node ReadFile}}]] [Op:IteratorGetNext] name: "
     ]
    }
   ],
   "source": [
    "# Generating predictions from the model above.\n",
    "\n",
    "final_cnn_pred = final_cnn.predict(test_dataset)\n",
    "final_cnn_pred = final_cnn_pred.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T6hAs7SlU9Zi",
    "outputId": "fb5f47fe-011c-44ec-ddb2-4c79c49d9e05"
   },
   "outputs": [],
   "source": [
    "# Generating a confusion matrix based on above predictions.\n",
    "\n",
    "conf_mat = confusion_matrix(test_labels_list, final_cnn_pred)\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uACH8n6fU95F"
   },
   "outputs": [],
   "source": [
    "# Defining a function to plot the confusion matrix in a grid for easier visualization.\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion Matrix', export_as='confusion_matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    # print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True labels', fontsize=14)\n",
    "    plt.xlabel('Predicted labels', fontsize=14)\n",
    "\n",
    "    # Exporting plot image in PNG format.\n",
    "    plt.savefig(f'/content/drive/MyDrive/1.1_age_input_output/output/cnn_logs/{export_as}.png', bbox_inches='tight');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 620
    },
    "id": "J1XROLD_U91Z",
    "outputId": "33361272-b755-4ac1-c8b5-611a8077f9d3"
   },
   "outputs": [],
   "source": [
    "# Plotting the confusion matrix using the function defined above.\n",
    "\n",
    "cm_plot_labels = ['1-2', '3-9', '10-20', '21-27', '28-45', '46-65', '66-116']\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plot_confusion_matrix(conf_mat, cm_plot_labels, normalize=True,\n",
    "                      title=\"Confusion Matrix based on predictions from CNN model\",\n",
    "                      export_as=\"final_cnn_conf_mat_norm\"\n",
    "                     )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DmI-BiMfM95q"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
